{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14661301,"sourceType":"datasetVersion","datasetId":9366204},{"sourceId":14663038,"sourceType":"datasetVersion","datasetId":9367384},{"sourceId":14666634,"sourceType":"datasetVersion","datasetId":9369837},{"sourceId":14679550,"sourceType":"datasetVersion","datasetId":9366260},{"sourceId":294801508,"sourceType":"kernelVersion"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:12.282160Z","iopub.execute_input":"2026-01-30T17:40:12.282393Z","iopub.status.idle":"2026-01-30T17:40:15.637037Z","shell.execute_reply.started":"2026-01-30T17:40:12.282369Z","shell.execute_reply":"2026-01-30T17:40:15.636111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nfrom pathlib import Path\nimport random\n\n\n\nINPUT_IMAGES = Path(\"/kaggle/input/vehicles-images/Images\")\nINPUT_LABELS = Path(\"/kaggle/input/labels/labels\")\n\n# Output clean filtered structure\nOUTPUT_BASE   = Path(\"/kaggle/working/filtered_dataset\")\nOUTPUT_IMAGES = OUTPUT_BASE / \"images\"\nOUTPUT_LABELS = OUTPUT_BASE / \"labels\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:15.638911Z","iopub.execute_input":"2026-01-30T17:40:15.639179Z","iopub.status.idle":"2026-01-30T17:40:15.644885Z","shell.execute_reply.started":"2026-01-30T17:40:15.639148Z","shell.execute_reply":"2026-01-30T17:40:15.643852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labeled_pairs = []\n\nfor txt_path in INPUT_LABELS.glob(\"*.txt\"):\n    stem = txt_path.stem\n    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n        img_path = INPUT_IMAGES / f\"{stem}{ext}\"\n        if img_path.exists():\n            labeled_pairs.append((img_path, txt_path))\n            break\n\nprint(f\"Found {len(labeled_pairs)} images with matching labels\")\n\nif not labeled_pairs:\n    raise ValueError(\"No image-label pairs found! Check folder names/paths.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:15.646094Z","iopub.execute_input":"2026-01-30T17:40:15.646628Z","iopub.status.idle":"2026-01-30T17:40:16.233907Z","shell.execute_reply.started":"2026-01-30T17:40:15.646603Z","shell.execute_reply":"2026-01-30T17:40:16.233156Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ────────────────────────────────────────────────\n# Step 2: Random shuffle + split into train / val\n# ────────────────────────────────────────────────\nTRAIN_RATIO = 0.8\n\nrandom.seed(42)  # for reproducibility\nrandom.shuffle(labeled_pairs)\n\nsplit_idx = int(len(labeled_pairs) * TRAIN_RATIO)\n\ntrain_pairs = labeled_pairs[:split_idx]\nval_pairs   = labeled_pairs[split_idx:]\n\nprint(f\"→ Train: {len(train_pairs)} images\")\nprint(f\"→ Val:   {len(val_pairs)} images\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:16.234825Z","iopub.execute_input":"2026-01-30T17:40:16.235186Z","iopub.status.idle":"2026-01-30T17:40:16.240538Z","shell.execute_reply.started":"2026-01-30T17:40:16.235162Z","shell.execute_reply":"2026-01-30T17:40:16.239857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ────────────────────────────────────────────────\n# Step 3: Create folders and copy only labeled files\n# ────────────────────────────────────────────────\n\nfor p in [\n    OUTPUT_IMAGES / \"train\", OUTPUT_IMAGES / \"val\",\n    OUTPUT_LABELS / \"train\", OUTPUT_LABELS / \"val\"\n]:\n    p.mkdir(parents=True, exist_ok=True)\n\ndef safe_copy(src, dst):\n    if src.exists():\n        shutil.copy(src, dst)\n    else:\n        print(f\"Warning: Source not found → {src}\")\n\nfor img_src, txt_src in train_pairs:\n    safe_copy(img_src, OUTPUT_IMAGES / \"train\" / img_src.name)\n    safe_copy(txt_src, OUTPUT_LABELS / \"train\" / txt_src.name)\n\nfor img_src, txt_src in val_pairs:\n    safe_copy(img_src, OUTPUT_IMAGES / \"val\" / img_src.name)\n    safe_copy(txt_src, OUTPUT_LABELS / \"val\" / txt_src.name)\n\nprint(\"Filtering and copying completed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:16.242555Z","iopub.execute_input":"2026-01-30T17:40:16.243161Z","iopub.status.idle":"2026-01-30T17:40:21.012032Z","shell.execute_reply.started":"2026-01-30T17:40:16.243137Z","shell.execute_reply":"2026-01-30T17:40:21.011363Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yaml\n\ndataset_yaml_content = {\n    'path': str(OUTPUT_BASE),          # /kaggle/working/filtered_dataset\n    'train': 'images/train',\n    'val': 'images/val',\n    'nc': 11,\n    'names': [\n        'Auto Rickshaw',\n        'Cycle Rickshaw',\n        'CNG/Tempo',\n        'Bus',\n        'Jeep/SUV',\n        'Microbus',\n        'Minibus',\n        'Motorcycle',\n        'Truck',\n        'Private Sedan Car',\n        'Trailer'\n    ]\n}\n\nyaml_file = \"/kaggle/working/data.yaml\"\n\nwith open(yaml_file, 'w') as f:\n    yaml.dump(dataset_yaml_content, f, default_flow_style=False, sort_keys=False)\n\nprint(\"Created data.yaml:\")\nprint(open(yaml_file).read())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:21.012995Z","iopub.execute_input":"2026-01-30T17:40:21.013186Z","iopub.status.idle":"2026-01-30T17:40:21.042158Z","shell.execute_reply.started":"2026-01-30T17:40:21.013167Z","shell.execute_reply":"2026-01-30T17:40:21.041367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\n\nIMAGES_DIR = \"/kaggle/working/filtered_dataset/images/train\"\nLABELS_DIR = \"/kaggle/working/filtered_dataset/labels/train\"\n\nCLASS_NAMES = [\n    'Auto Rickshaw',\n    'Cycle Rickshaw',\n    'CNG/Tempo',\n    'Bus',\n    'Jeep/SUV',\n    'Microbus',\n    'Minibus',\n    'Motorcycle',\n    'Truck',\n    'Private Sedan Car',\n    'Trailer'\n]\n\ndef visualize_any_sample_hd():\n    image_name = next(f for f in os.listdir(IMAGES_DIR) if f.endswith((\".jpg\", \".png\")))\n\n    img_path = os.path.join(IMAGES_DIR, image_name)\n    label_path = os.path.join(LABELS_DIR, image_name.rsplit(\".\", 1)[0] + \".txt\")\n\n    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    h, w, _ = img.shape\n\n    with open(label_path, \"r\") as f:\n        for line in f:\n            cls, x, y, bw, bh = map(float, line.split())\n            cls = int(cls)\n\n            x1 = int((x - bw / 2) * w)\n            y1 = int((y - bh / 2) * h)\n            x2 = int((x + bw / 2) * w)\n            y2 = int((y + bh / 2) * h)\n\n            # thicker box + anti-aliasing\n            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3, cv2.LINE_AA)\n            cv2.putText(\n                img,\n                CLASS_NAMES[cls],\n                (x1, max(y1 - 8, 20)),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                0.8,\n                (255, 0, 0),\n                2,\n                cv2.LINE_AA\n            )\n\n    # High DPI rendering (KEY FIX)\n    plt.figure(figsize=(12, 12), dpi=200)\n    plt.imshow(img, interpolation=\"nearest\")\n    plt.axis(\"off\")\n    plt.show()\n\n\nvisualize_any_sample_hd()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:21.043209Z","iopub.execute_input":"2026-01-30T17:40:21.043483Z","iopub.status.idle":"2026-01-30T17:40:22.381978Z","shell.execute_reply.started":"2026-01-30T17:40:21.043461Z","shell.execute_reply":"2026-01-30T17:40:22.381133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO(\"yolo26n.pt\")   # or yolo26s.pt if you want slightly better accuracy\n\nresults = model.train(\n    data     = \"/kaggle/working/data.yaml\",\n    epochs   = 100,               # smaller dataset → 60–120 epochs is usually enough\n    imgsz    = 640,\n    batch    = 12,               # lower if you get OOM error\n    device   = 0,\n    patience = 25,\n    optimizer = \"AdamW\",\n    lr0      = 0.001,\n    amp      = True,\n    mosaic   = 1.0,\n    mixup    = 0.15,\n    hsv_h    = 0.015,\n    hsv_s    = 0.7,\n    hsv_v    = 0.4,\n    degrees  = 8.0,\n    translate= 0.1,\n    scale    = 0.6,\n    shear    = 2.0,\n    flipud   = 0.4,\n    fliplr   = 0.5,\n    save_period = 10\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:22.383211Z","iopub.execute_input":"2026-01-30T17:40:22.383595Z","iopub.status.idle":"2026-01-30T17:40:22.399565Z","shell.execute_reply.started":"2026-01-30T17:40:22.383553Z","shell.execute_reply":"2026-01-30T17:40:22.398465Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\nmodel = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:22.400152Z","iopub.status.idle":"2026-01-30T17:40:22.400426Z","shell.execute_reply.started":"2026-01-30T17:40:22.400300Z","shell.execute_reply":"2026-01-30T17:40:22.400322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nval_images_dir = Path('/kaggle/working/filtered_dataset/images/val')\nimage_paths = list(val_images_dir.glob('*.jpg')) + list(val_images_dir.glob('*.png'))\n \nprint(f\"Found {len(image_paths)} validation images.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:22.401412Z","iopub.status.idle":"2026-01-30T17:40:22.401829Z","shell.execute_reply.started":"2026-01-30T17:40:22.401600Z","shell.execute_reply":"2026-01-30T17:40:22.401627Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run inference and save results to a folder\nresults = model.predict(source=str(val_images_dir), conf=0.1, imgsz=640, save=True, save_txt=True, project='/kaggle/working/runs/detect/val_pred', name='results', exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:22.402683Z","iopub.status.idle":"2026-01-30T17:40:22.402968Z","shell.execute_reply.started":"2026-01-30T17:40:22.402855Z","shell.execute_reply":"2026-01-30T17:40:22.402868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\n\npred_dir = \"/kaggle/working/runs/detect/val_pred/results\"\nimage_exts = (\".jpg\", \".jpeg\", \".png\")\n\nfor img_name in sorted(os.listdir(pred_dir)):\n    if not img_name.lower().endswith(image_exts):\n        continue  # skip non-image files\n\n    img_path = os.path.join(pred_dir, img_name)\n    img = cv2.imread(img_path)\n\n    if img is None:\n        print(f\"⚠️ Could not read: {img_name}\")\n        continue\n\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    plt.figure(figsize=(6, 6))\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.title(img_name)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:22.404033Z","iopub.status.idle":"2026-01-30T17:40:22.404323Z","shell.execute_reply.started":"2026-01-30T17:40:22.404204Z","shell.execute_reply":"2026-01-30T17:40:22.404219Z"}},"outputs":[],"execution_count":null}]}